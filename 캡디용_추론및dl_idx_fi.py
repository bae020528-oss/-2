# -*- coding: utf-8 -*-
"""ìº¡ë””ìš©_ì¶”ë¡ ë°dl_idx_fi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_PQ1Mm7TRgTGsdeIzcvUJ0XQDnt30zdd
"""

!pip install ultralytics

# === Fast Inference API (Optimized):
#     YOLO â†’ (ì¡°ê±´ë¶€ ì „ì²´ì´ë¯¸ì§€ / ì†Œí”„íŠ¸ í¬ë¡­)
#     â†’ ResNet(1324) ìµœì¢… Top-5 (dl_idx ê³„ì‚°ì‹ ê¸°ë°˜) ===
# -*- coding: utf-8 -*-
import os
import json
from pathlib import Path

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms

from ultralytics import YOLO
from PIL import Image

# -------------------------------------------------
# 0) ê²½ë¡œ / ê¸°ë³¸ ì„¤ì •
# -------------------------------------------------
DRIVE = "/content/drive/MyDrive"

# í…ŒìŠ¤íŠ¸ìš© ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (í•„ìš”í•˜ë©´ ì´ ê°’ë§Œ ë°”ê¿”ì„œ ì‚¬ìš©)
IMG_PATH = "/content/drive/MyDrive/á„á…¢á†¸á„‰á…³á„á…©á†«_á„‹á…¯á†«á„á…¥á†«_á„ƒá…¦á„‹á…µá„á…¥/TS_34_á„ƒá…¡á†«á„‹á…µá†¯.zip/K-009272/K-009272_0_1_0_0_70_000_200.png"

BEST_YOLO      = os.path.join(DRIVE, "best.pt")
RESNET_1324_PT = os.path.join(DRIVE, "best_model_generalized.pth")
CLASS_JSON_1K  = os.path.join(DRIVE, "pill_label_path_sharp_score.json")
CLASS_JSON_324 = os.path.join(DRIVE, "class_mapping_from_cache_1324.json")

for p in [BEST_YOLO, RESNET_1324_PT]:
    assert os.path.exists(p), f"ê°€ì¤‘ì¹˜ íŒŒì¼ ì—†ìŒ: {p}"

YOLO_CONF  = 0.25
YOLO_IOU   = 0.45
YOLO_IMGSZ = 640

CROP_SIZE        = 224
MIN_BOX_SIDE_PX  = 40
FULL_IMAGE_AREA_RATIO_THRESHOLD = 0.65
SQUARE_SCALE     = 1.3

NUM_CLASSES  = 1324
LABEL_OFFSET = 1000

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", DEVICE)

# -------------------------------------------------
# 1) ë¼ë²¨ ë§µ ë¡œë“œ (class_idx â†’ K-ì½”ë“œ)
#    ê·¸ë¦¬ê³  ìµœì¢… dl_idxëŠ” "K-xxxxxx"ì˜ ë’¤ 6ìë¦¬ ì •ìˆ˜ - 1 ë¡œ ê³„ì‚°
#    âš ï¸ ì´ ë¶€ë¶„ë„ í•œ ë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ ì „ì—­ì—ì„œ ì‹¤í–‰
# -------------------------------------------------
def load_label_map_generic(json_path):
    """
    pill_label_path_sharp_score.json / class_mapping_from_cache_1324.json ì„ ì½ì–´ì„œ
    class_idx â†’ Kì½”ë“œ(K-xxxxxx) ë§¤í•‘ì„ ë§Œë“ ë‹¤.
    ê°’ì´ ê²½ë¡œ/íŒŒì¼ëª…ì¼ ê²½ìš° íŒŒì¼ëª…ì—ì„œ Kì½”ë“œë¥¼ íŒŒì‹±í•´ì„œ ì‚¬ìš©.
    """
    if not json_path or not os.path.exists(json_path):
        return {}
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    if isinstance(data, dict) and "label_to_kcode" in data:
        data = data["label_to_kcode"]

    out = {}
    if isinstance(data, dict):
        for k, v in data.items():
            try:
                key_int = int(k)
            except:
                continue

            val_str = str(v)
            base = os.path.basename(val_str)   # ì˜ˆ: "K013101_0_2_0_1_90_020_200.png"
            first = base.split("_")[0]         # ì˜ˆ: "K013101" ë˜ëŠ” "K-009272"

            if first.startswith("K-") and len(first) == 8 and first[2:].isdigit():
                # ì´ë¯¸ "K-009272" ê°™ì€ í˜•ì‹
                kcode = first
            elif first.startswith("K") and len(first) == 7 and first[1:].isdigit():
                # "K013101" â†’ "K-013101"
                kcode = "K-" + first[1:]
            else:
                # ê·¸ ì™¸ì—ëŠ” ê·¸ëƒ¥ ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš© (fallback)
                kcode = first

            out[key_int] = kcode

    return out

LABEL_MAP_1K  = load_label_map_generic(CLASS_JSON_1K)   # 0..999 â†’ Kì½”ë“œ
LABEL_MAP_324 = load_label_map_generic(CLASS_JSON_324)  # 0..323 â†’ Kì½”ë“œ (1000~1323ìš©)

def class_idx_to_kcode(global_idx: int) -> str:
    """
    ëª¨ë¸ì˜ global class index â†’ Kì½”ë“œ(K-xxxxxx)ë¡œ ë³€í™˜
    """
    if global_idx < LABEL_OFFSET:
        return LABEL_MAP_1K.get(global_idx, f"imagenet_{global_idx}")
    local = global_idx - LABEL_OFFSET
    return LABEL_MAP_324.get(local, f"unknown_{local}")

def kcode_to_dl_idx(kcode: str) -> str:
    """
    Kì½”ë“œì—ì„œ dl_idx ê³„ì‚°:
      ì˜ˆ) "K-009272" â†’ ë’¤ 6ìë¦¬ 009272 â†’ 9272 - 1 = 9271
    ë§¤í•‘ íŒŒì¼ ì—†ì´ ê·œì¹™ìœ¼ë¡œë§Œ ê³„ì‚°.
    """
    if len(kcode) >= 7:
        tail = kcode[-6:]  # ë 6ìë¦¬
        if tail.isdigit():
            val = int(tail)
            dl_val = val - 1
            if dl_val >= 0:
                return str(dl_val)
    # ì‹¤íŒ¨ ì‹œ ê·¸ëƒ¥ ì›ë˜ ë¬¸ìì—´ ë°˜í™˜ (ë””ë²„ê·¸ìš©)
    return kcode

def idx_to_dl_idx(global_idx: int) -> str:
    """
    class index â†’ Kì½”ë“œ â†’ dl_idx ë¡œ ë³€í™˜
    """
    kcode = class_idx_to_kcode(global_idx)
    return kcode_to_dl_idx(kcode)

# -------------------------------------------------
# 2) ResNet 1324 ëª¨ë¸ + ì „ì²˜ë¦¬ (ì „ì—­ 1íšŒ ë¡œë“œ)
# -------------------------------------------------
def build_resnet_1324(num_classes=NUM_CLASSES, model_path=RESNET_1324_PT):
    model = models.resnet152(weights=None)
    in_f = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(p=0.5),
        nn.Linear(in_f, num_classes)
    )

    state = torch.load(model_path, map_location="cpu")
    if isinstance(state, dict):
        if "model_state_dict" in state:
            state = state["model_state_dict"]
        elif "model" in state:
            state = state["model"]
    missing, unexpected = model.load_state_dict(state, strict=False)
    if missing or unexpected:
        print(f"â„¹ï¸ state_dict load: missing={len(missing)}, unexpected={len(unexpected)}")

    model.to(DEVICE)
    model.eval()

    # GPUë©´ half precisionìœ¼ë¡œ ì‚´ì§ ë” ë¹ ë¥´ê²Œ
    if DEVICE.type == "cuda":
        model.half()

    return model

# ğŸ”¥ ì „ì—­ì—ì„œ í•œ ë²ˆë§Œ ìƒì„±í•´ì„œ ì¬ì‚¬ìš©
RESNET_MODEL = build_resnet_1324()

# ì „ì—­ transform (ì´ë¯¸ì§€ â†’ í…ì„œ)
base_transform = transforms.Compose([
    transforms.Resize((CROP_SIZE, CROP_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

def preprocess_pil(pil_img):
    t = base_transform(pil_img)
    # ëª¨ë¸ì´ halfë©´ ì…ë ¥ë„ halfë¡œ ë§ì¶”ê¸°
    if DEVICE.type == "cuda":
        return t.half()
    return t

@torch.no_grad()
def predict_resnet_batch(pil_imgs, topk=5):
    """
    ì „ì—­ RESNET_MODEL ì‚¬ìš©.
    pil_imgs: [PIL.Image, ...]
    """
    if not pil_imgs:
        return []
    xs = [preprocess_pil(im) for im in pil_imgs]
    x = torch.stack(xs).to(DEVICE)

    # ì´ë¯¸ halfë¡œ ì˜¬ë ¤ë†¨ìœ¼ë©´ autocast í•„ìš” ì—†ìŒ â†’ ì˜¤ë²„í—¤ë“œ ì¤„ì´ê¸°
    if DEVICE.type == 'cuda':
        logits = RESNET_MODEL(x)
    else:
        with torch.amp.autocast(device_type='cpu'):
            logits = RESNET_MODEL(x)

    probs  = F.softmax(logits, dim=1)
    topk_prob, topk_idx = torch.topk(probs, topk, dim=1)

    all_results = []
    for i in range(probs.shape[0]):
        res_i = []
        for p, idx in zip(topk_prob[i].tolist(), topk_idx[i].tolist()):
            res_i.append({
                "idx": int(idx),
                "prob": float(p),
            })
        all_results.append(res_i)
    return all_results

# -------------------------------------------------
# 3) YOLO ê°ì§€ + í¬ë¡­ ìƒì„± (ì „ì—­ YOLO 1íšŒ ë¡œë“œ, ë©”ëª¨ë¦¬ ìƒ ì²˜ë¦¬)
# -------------------------------------------------
# YOLOë„ ì „ì—­ì—ì„œ í•œ ë²ˆë§Œ ë¡œë“œ
YOLO_DEVICE = 0 if DEVICE.type == "cuda" else "cpu"
YOLO_MODEL = YOLO(BEST_YOLO)  # ultralyticsê°€ ë‚´ë¶€ì—ì„œ device ì¸ìì— ë”°ë¼ ì²˜ë¦¬

def square_crop_from_bbox(pil_img, xyxy, scale=1.3):
    W, H = pil_img.size
    x1, y1, x2, y2 = xyxy
    cx = (x1 + x2) / 2.0
    cy = (y1 + y2) / 2.0
    bw = x2 - x1
    bh = y2 - y1
    side = max(bw, bh) * scale

    # ìµœì†Œ ì‚¬ì´ì¦ˆ ë³´ì¥
    side = max(side, MIN_BOX_SIDE_PX * 1.5)

    half = side / 2.0
    nx1 = int(round(cx - half))
    ny1 = int(round(cy - half))
    nx2 = int(round(cx + half))
    ny2 = int(round(cy + half))

    nx1 = max(0, nx1)
    ny1 = max(0, ny1)
    nx2 = min(W, nx2)
    ny2 = min(H, ny2)
    if nx2 <= nx1 or ny2 <= ny1:
        return None

    crop = pil_img.crop((nx1, ny1, nx2, ny2))
    return crop

def make_crops_with_yolo(img_path):
    """
    IMG_PATH í•˜ë‚˜ ë°›ì•„ì„œ:
      - YOLOë¡œ bbox ê²€ì¶œ
      - ë‹¨ì¼ + ê±°ì˜ ì „ì²´ ì°¨ì§€ë©´ full ì´ë¯¸ì§€ 1ì¥
      - ê·¸ ì™¸ì—” square crop ì—¬ëŸ¬ ì¥
    ê²°ê³¼: [PIL.Image, ...]
    """
    assert os.path.exists(img_path), f"ì´ë¯¸ì§€ ì—†ìŒ: {img_path}"

    det = YOLO_MODEL(
        img_path,
        imgsz=YOLO_IMGSZ,
        conf=YOLO_CONF,
        iou=YOLO_IOU,
        device=YOLO_DEVICE,
        verbose=False
    )[0]

    img = Image.open(img_path).convert("RGB")
    W, H = img.size
    img_area = W * H

    raw_boxes = []
    if det.boxes is not None and len(det.boxes) > 0:
        for b in det.boxes.xyxy.cpu().numpy().tolist():
            x1, y1, x2, y2 = map(int, b)
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(W-1, x2)
            y2 = min(H-1, y2)
            if (x2-x1) >= MIN_BOX_SIDE_PX and (y2-y1) >= MIN_BOX_SIDE_PX:
                raw_boxes.append([x1, y1, x2, y2])

    # ë‹¨ì¼ í° ë°•ìŠ¤ë©´ ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©
    use_full_image_only = False
    if len(raw_boxes) == 1:
        x1, y1, x2, y2 = raw_boxes[0]
        box_area = (x2-x1) * (y2-y1)
        area_ratio = box_area / float(img_area + 1e-9)
        if area_ratio >= FULL_IMAGE_AREA_RATIO_THRESHOLD:
            use_full_image_only = True

    crop_images = []

    if use_full_image_only:
        crop_images.append(img.copy())
    else:
        for bbox in raw_boxes:
            sq = square_crop_from_bbox(img, bbox, scale=SQUARE_SCALE) if raw_boxes else None
            if sq is None:
                continue
            crop_images.append(sq)

    # YOLOê°€ ì•„ë¬´ê²ƒë„ ëª» ì¡ì•˜ìœ¼ë©´ ì „ì²´ ì´ë¯¸ì§€ fallback
    if not crop_images:
        crop_images.append(img.copy())

    return crop_images

# -------------------------------------------------
# 4) ì—”ë“œíˆ¬ì—”ë“œ ì¶”ë¡  í•¨ìˆ˜ (APIë¡œ ì“°ê¸° ì¢‹ê²Œ)
# -------------------------------------------------
def infer_pill_image(img_path: str, topk_global: int = 5):
    """
    í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ê²½ë¡œ(img_path)ë¥¼ ë°›ì•„:
      - YOLOë¡œ ì†Œí”„íŠ¸ í¬ë¡­ ì—¬ëŸ¬ ê°œ ìƒì„±
      - ê° í¬ë¡­ì„ ResNet(1324)ë¡œ ì¶”ë¡ 
      - classë³„ max-poolingìœ¼ë¡œ ì „ì²´ ì´ë¯¸ì§€ ê¸°ì¤€ ìµœì¢… Top-K ê³„ì‚°
      - ìµœì¢… ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ return

    return í˜•ì‹:
      [
        {"rank": 1, "idx": <class_idx>, "dl_idx": "<dl_idx>", "prob": <float>},
        ...
      ]
    """
    # 1) í¬ë¡­ ìƒì„±
    crops = make_crops_with_yolo(img_path)

    # 2) í¬ë¡­ë³„ Top-5 (ì „ì—­ RESNET_MODEL ì‚¬ìš©)
    batch_results = predict_resnet_batch(crops, topk=topk_global)

    # 3) í´ë˜ìŠ¤ë³„ max-pooling
    agg_scores = {}  # class_idx â†’ max_prob
    for crop_res in batch_results:
        for t in crop_res:
            idx = t["idx"]
            p   = t["prob"]
            if idx not in agg_scores or p > agg_scores[idx]:
                agg_scores[idx] = p

    if not agg_scores:
        return []

    # 4) ì „ì²´ ì´ë¯¸ì§€ ê¸°ì¤€ ìµœì¢… Top-K
    sorted_pairs = sorted(agg_scores.items(), key=lambda x: x[1], reverse=True)[:topk_global]

    final_results = []
    for rank, (idx, prob) in enumerate(sorted_pairs, start=1):
        dl_idx = idx_to_dl_idx(idx)
        final_results.append({
            "rank":  rank,
            "idx":   idx,
            "dl_idx": dl_idx,
            "prob":  prob,
        })

    return final_results

# -------------------------------------------------
# 5) ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ ë™ì‘ ì˜ˆì‹œ
# -------------------------------------------------
if __name__ == "__main__":
    assert os.path.exists(IMG_PATH), f"ì´ë¯¸ì§€ ì—†ìŒ: {IMG_PATH}"
    results = infer_pill_image(IMG_PATH, topk_global=5)

    # âœ… APIì— ë„˜ê¸¸ ê°’ì€ ì´ results ê·¸ëŒ€ë¡œ ì“°ë©´ ë¨
    print("=== FINAL GLOBAL TOP-5 RESULTS ===")
    for r in results:
        print(
            f"Rank {r['rank']}: "
            f"class_idx={r['idx']}, dl_idx={r['dl_idx']}, prob={r['prob']*100:.2f}%"
        )
    # import json
    # print(json.dumps(results, ensure_ascii=False, indent=2))