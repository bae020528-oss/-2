# -*- coding: utf-8 -*-
"""ìº¡ë””ìš©_ì¶”ë¡ ë°dl_idx_fi_ë‹¤ì¤‘ì•Œì•½

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yDcHR9MImuJ2a5-4oSfP3qe_76myNAMo
"""

# === Fast Inference API (Optimized + Multi-pill):
#     YOLO â†’ (ì¡°ê±´ë¶€ ì „ì²´ì´ë¯¸ì§€ / ì†Œí”„íŠ¸ í¬ë¡­)
#     â†’ ResNet(1324) ë‹¨ì¼/ë‹¤ì¤‘ ì•Œì•½ ë¶„ë¥˜ (dl_idx ê³„ì‚°ì‹ ê¸°ë°˜) ===
# -*- coding: utf-8 -*-
import os
import json
from pathlib import Path

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms

from ultralytics import YOLO
from PIL import Image

# -------------------------------------------------
# 0) ê²½ë¡œ / ê¸°ë³¸ ì„¤ì •
# -------------------------------------------------
DRIVE = "/content/drive/MyDrive"

# í…ŒìŠ¤íŠ¸ìš© ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (í•„ìš”í•˜ë©´ ì´ ê°’ë§Œ ë°”ê¿”ì„œ ì‚¬ìš©)
IMG_PATH = "/content/drive/MyDrive/á„á…¢á†¸á„‰á…³á„á…©á†«_á„‹á…¯á†«á„á…¥á†«_á„ƒá…¦á„‹á…µá„á…¥/TS_48_á„ƒá…¡á†«á„‹á…µá†¯.zip/K-018357/K-018357_0_2_0_0_70_000_200.png"

BEST_YOLO      = os.path.join(DRIVE, "best.pt")
RESNET_1324_PT = os.path.join(DRIVE, "best_model_generalized.pth")
CLASS_JSON_1K  = os.path.join(DRIVE, "pill_label_path_sharp_score.json")
CLASS_JSON_324 = os.path.join(DRIVE, "class_mapping_from_cache_1324.json")

for p in [BEST_YOLO, RESNET_1324_PT]:
    assert os.path.exists(p), f"ê°€ì¤‘ì¹˜ íŒŒì¼ ì—†ìŒ: {p}"

YOLO_CONF  = 0.25
YOLO_IOU   = 0.45
YOLO_IMGSZ = 640

CROP_SIZE        = 224
MIN_BOX_SIDE_PX  = 40
FULL_IMAGE_AREA_RATIO_THRESHOLD = 0.65
SQUARE_SCALE     = 1.3

NUM_CLASSES  = 1324
LABEL_OFFSET = 1000

MAX_PILLS_MULTI = 4  # ë‹¤ì¤‘ ì•Œì•½ ëª¨ë“œì—ì„œ ìµœëŒ€ ì•Œì•½ ê°œìˆ˜

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", DEVICE)

# -------------------------------------------------
# 1) ë¼ë²¨ ë§µ ë¡œë“œ (class_idx â†’ K-ì½”ë“œ)
#    ê·¸ë¦¬ê³  ìµœì¢… dl_idxëŠ” "K-xxxxxx"ì˜ ë’¤ 6ìë¦¬ ì •ìˆ˜ - 1 ë¡œ ê³„ì‚°
# -------------------------------------------------
def load_label_map_generic(json_path):
    """
    pill_label_path_sharp_score.json / class_mapping_from_cache_1324.json ì„ ì½ì–´ì„œ
    class_idx â†’ Kì½”ë“œ(K-xxxxxx) ë§¤í•‘ì„ ë§Œë“ ë‹¤.
    ê°’ì´ ê²½ë¡œ/íŒŒì¼ëª…ì¼ ê²½ìš° íŒŒì¼ëª…ì—ì„œ Kì½”ë“œë¥¼ íŒŒì‹±í•´ì„œ ì‚¬ìš©.
    """
    if not json_path or not os.path.exists(json_path):
        return {}
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    if isinstance(data, dict) and "label_to_kcode" in data:
        data = data["label_to_kcode"]

    out = {}
    if isinstance(data, dict):
        for k, v in data.items():
            try:
                key_int = int(k)
            except:
                continue

            val_str = str(v)
            base = os.path.basename(val_str)   # ì˜ˆ: "K013101_0_2_0_1_90_020_200.png"
            first = base.split("_")[0]         # ì˜ˆ: "K013101" ë˜ëŠ” "K-009272"

            if first.startswith("K-") and len(first) == 8 and first[2:].isdigit():
                # ì´ë¯¸ "K-009272" ê°™ì€ í˜•ì‹
                kcode = first
            elif first.startswith("K") and len(first) == 7 and first[1:].isdigit():
                # "K013101" â†’ "K-013101"
                kcode = "K-" + first[1:]
            else:
                # ê·¸ ì™¸ì—ëŠ” ê·¸ëƒ¥ ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš© (fallback)
                kcode = first

            out[key_int] = kcode

    return out

LABEL_MAP_1K  = load_label_map_generic(CLASS_JSON_1K)   # 0..999 â†’ Kì½”ë“œ
LABEL_MAP_324 = load_label_map_generic(CLASS_JSON_324)  # 0..323 â†’ Kì½”ë“œ (1000~1323ìš©)

def class_idx_to_kcode(global_idx: int) -> str:
    """
    ëª¨ë¸ì˜ global class index â†’ Kì½”ë“œ(K-xxxxxx)ë¡œ ë³€í™˜
    """
    if global_idx < LABEL_OFFSET:
        return LABEL_MAP_1K.get(global_idx, f"imagenet_{global_idx}")
    local = global_idx - LABEL_OFFSET
    return LABEL_MAP_324.get(local, f"unknown_{local}")

def kcode_to_dl_idx(kcode: str) -> str:
    """
    Kì½”ë“œì—ì„œ dl_idx ê³„ì‚°:
      ì˜ˆ) "K-009272" â†’ ë’¤ 6ìë¦¬ 009272 â†’ 9272 - 1 = 9271
    ë§¤í•‘ íŒŒì¼ ì—†ì´ ê·œì¹™ìœ¼ë¡œë§Œ ê³„ì‚°.
    """
    if len(kcode) >= 7:
        tail = kcode[-6:]  # ë 6ìë¦¬
        if tail.isdigit():
            val = int(tail)
            dl_val = val - 1
            if dl_val >= 0:
                return str(dl_val)
    # ì‹¤íŒ¨ ì‹œ ê·¸ëƒ¥ ì›ë˜ ë¬¸ìì—´ ë°˜í™˜ (ë””ë²„ê·¸ìš©)
    return kcode

def idx_to_dl_idx(global_idx: int) -> str:
    """
    class index â†’ Kì½”ë“œ â†’ dl_idx ë¡œ ë³€í™˜
    """
    kcode = class_idx_to_kcode(global_idx)
    return kcode_to_dl_idx(kcode)

# -------------------------------------------------
# 2) ResNet 1324 ëª¨ë¸ + ì „ì²˜ë¦¬ (ì „ì—­ 1íšŒ ë¡œë“œ)
# -------------------------------------------------
def build_resnet_1324(num_classes=NUM_CLASSES, model_path=RESNET_1324_PT):
    model = models.resnet152(weights=None)
    in_f = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(p=0.5),
        nn.Linear(in_f, num_classes)
    )

    state = torch.load(model_path, map_location="cpu")
    if isinstance(state, dict):
        if "model_state_dict" in state:
            state = state["model_state_dict"]
        elif "model" in state:
            state = state["model"]
    missing, unexpected = model.load_state_dict(state, strict=False)
    if missing or unexpected:
        print(f"â„¹ï¸ state_dict load: missing={len(missing)}, unexpected={len(unexpected)}")

    model.to(DEVICE)
    model.eval()

    # GPUë©´ half precisionìœ¼ë¡œ ì‚´ì§ ë” ë¹ ë¥´ê²Œ
    if DEVICE.type == "cuda":
        model.half()

    return model

# ğŸ”¥ ì „ì—­ì—ì„œ í•œ ë²ˆë§Œ ìƒì„±í•´ì„œ ì¬ì‚¬ìš©
RESNET_MODEL = build_resnet_1324()

# ì „ì—­ transform (ì´ë¯¸ì§€ â†’ í…ì„œ)
base_transform = transforms.Compose([
    transforms.Resize((CROP_SIZE, CROP_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

def preprocess_pil(pil_img):
    t = base_transform(pil_img)
    # ëª¨ë¸ì´ halfë©´ ì…ë ¥ë„ halfë¡œ ë§ì¶”ê¸°
    if DEVICE.type == "cuda":
        return t.half()
    return t

@torch.no_grad()
def predict_resnet_batch(pil_imgs, topk=5):
    """
    ì „ì—­ RESNET_MODEL ì‚¬ìš©.
    pil_imgs: [PIL.Image, ...]
    """
    if not pil_imgs:
        return []
    xs = [preprocess_pil(im) for im in pil_imgs]
    x = torch.stack(xs).to(DEVICE)

    if DEVICE.type == 'cuda':
        logits = RESNET_MODEL(x)
    else:
        with torch.amp.autocast(device_type='cpu'):
            logits = RESNET_MODEL(x)

    probs  = F.softmax(logits, dim=1)
    topk_prob, topk_idx = torch.topk(probs, topk, dim=1)

    all_results = []
    for i in range(probs.shape[0]):
        res_i = []
        for p, idx in zip(topk_prob[i].tolist(), topk_idx[i].tolist()):
            res_i.append({
                "idx": int(idx),
                "prob": float(p),
            })
        all_results.append(res_i)
    return all_results

# -------------------------------------------------
# 3) YOLO ê°ì§€ ê³µí†µ ë¡œì§ (ì „ì—­ YOLO 1íšŒ ë¡œë“œ)
# -------------------------------------------------
YOLO_DEVICE = 0 if DEVICE.type == "cuda" else "cpu"
YOLO_MODEL = YOLO(BEST_YOLO)

def detect_yolo_boxes(img_path):
    """
    YOLOë¡œ bbox + confidence ì¶”ì¶œ ê³µí†µ í•¨ìˆ˜.
    return:
      img (PIL),
      boxes: [[x1,y1,x2,y2], ...],
      confs: [float, ...]
    """
    assert os.path.exists(img_path), f"ì´ë¯¸ì§€ ì—†ìŒ: {img_path}"

    det = YOLO_MODEL(
        img_path,
        imgsz=YOLO_IMGSZ,
        conf=YOLO_CONF,
        iou=YOLO_IOU,
        device=YOLO_DEVICE,
        verbose=False
    )[0]

    img = Image.open(img_path).convert("RGB")
    W, H = img.size

    boxes = []
    confs = []

    if det.boxes is not None and len(det.boxes) > 0:
        xyxy = det.boxes.xyxy.cpu().numpy().tolist()
        conf = det.boxes.conf.cpu().numpy().tolist()
        for (b, c) in zip(xyxy, conf):
            x1, y1, x2, y2 = map(int, b)
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(W-1, x2)
            y2 = min(H-1, y2)
            if (x2-x1) >= MIN_BOX_SIDE_PX and (y2-y1) >= MIN_BOX_SIDE_PX:
                boxes.append([x1, y1, x2, y2])
                confs.append(float(c))

    return img, boxes, confs

def square_crop_from_bbox(pil_img, xyxy, scale=1.3):
    W, H = pil_img.size
    x1, y1, x2, y2 = xyxy
    cx = (x1 + x2) / 2.0
    cy = (y1 + y2) / 2.0
    bw = x2 - x1
    bh = y2 - y1
    side = max(bw, bh) * scale

    # ìµœì†Œ ì‚¬ì´ì¦ˆ ë³´ì¥
    side = max(side, MIN_BOX_SIDE_PX * 1.5)

    half = side / 2.0
    nx1 = int(round(cx - half))
    ny1 = int(round(cy - half))
    nx2 = int(round(cx + half))
    ny2 = int(round(cy + half))

    nx1 = max(0, nx1)
    ny1 = max(0, ny1)
    nx2 = min(W, nx2)
    ny2 = min(H, ny2)
    if nx2 <= nx1 or ny2 <= ny1:
        return None

    crop = pil_img.crop((nx1, ny1, nx2, ny2))
    return crop

# -------------------------------------------------
# 4-A) ë‹¨ì¼ ì•Œì•½ ëª¨ë“œ: ì´ë¯¸ì§€ ì „ì²´ ê¸°ì¤€ Top-K (ê¸°ì¡´ infer_pill_image)
# -------------------------------------------------
def make_crops_for_single_mode(img_path):
    """
    ë‹¨ì¼ ì•Œì•½ ë˜ëŠ” "ì‹¤ì§ˆì ìœ¼ë¡œ í•˜ë‚˜ë§Œ ìˆëŠ”" ì´ë¯¸ì§€ì— ëŒ€í•´,
    - YOLOë¡œ bbox íƒì§€
    - ë‹¨ì¼ + ê±°ì˜ ì „ì²´ ì°¨ì§€ë©´ full ì´ë¯¸ì§€ 1ì¥
    - ê·¸ ì™¸ì—” bboxë§ˆë‹¤ square crop
    """
    img, boxes, _ = detect_yolo_boxes(img_path)
    W, H = img.size
    img_area = W * H

    # ë‹¨ì¼ í° ë°•ìŠ¤ë©´ ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©
    use_full_image_only = False
    if len(boxes) == 1:
        x1, y1, x2, y2 = boxes[0]
        box_area = (x2-x1) * (y2-y1)
        area_ratio = box_area / float(img_area + 1e-9)
        if area_ratio >= FULL_IMAGE_AREA_RATIO_THRESHOLD:
            use_full_image_only = True

    crop_images = []
    if use_full_image_only:
        crop_images.append(img.copy())
    else:
        for bbox in boxes:
            sq = square_crop_from_bbox(img, bbox, scale=SQUARE_SCALE) if boxes else None
            if sq is None:
                continue
            crop_images.append(sq)

    if not crop_images:
        crop_images.append(img.copy())

    return crop_images

def infer_pill_image_single(img_path: str, topk_global: int = 5):
    """
    [ê¸°ì¡´ ê¸°ëŠ¥] ì´ë¯¸ì§€ ì „ì²´ ê¸°ì¤€ìœ¼ë¡œ ìµœì¢… Top-Kë§Œ ë½‘ëŠ” ëª¨ë“œ.
    ì—¬ëŸ¬ cropì„ ë§Œë“  ë’¤, classë³„ max-poolingìœ¼ë¡œ í†µí•©.
    """
    crops = make_crops_for_single_mode(img_path)
    batch_results = predict_resnet_batch(crops, topk=topk_global)

    # í´ë˜ìŠ¤ë³„ max-pooling
    agg_scores = {}  # class_idx â†’ max_prob
    for crop_res in batch_results:
        for t in crop_res:
            idx = t["idx"]
            p   = t["prob"]
            if idx not in agg_scores or p > agg_scores[idx]:
                agg_scores[idx] = p

    if not agg_scores:
        return []

    sorted_pairs = sorted(agg_scores.items(), key=lambda x: x[1], reverse=True)[:topk_global]

    final_results = []
    for rank, (idx, prob) in enumerate(sorted_pairs, start=1):
        dl_idx = idx_to_dl_idx(idx)
        final_results.append({
            "rank":  rank,
            "idx":   idx,
            "dl_idx": dl_idx,
            "prob":  prob,
        })

    return final_results

# -------------------------------------------------
# 4-B) ë‹¤ì¤‘ ì•Œì•½ ëª¨ë“œ: ìµœëŒ€ 4ê°œ ì•Œì•½ ê°ê°ì— ëŒ€í•œ Top-K
# -------------------------------------------------
def infer_pill_image_multi(img_path: str, max_pills: int = MAX_PILLS_MULTI, topk: int = 5):
    """
    ì´ë¯¸ì§€ ì•ˆì— ìµœëŒ€ max_pills ê°œì˜ ì•Œì•½ì´ ìˆì„ ìˆ˜ ìˆëŠ” ê²½ìš°:
      - YOLOë¡œ bbox + conf íƒì§€
      - conf ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ max_pills ê°œ ì„ íƒ
      - ê° bboxë§ˆë‹¤ crop â†’ ResNet Top-K
      - ì•Œì•½ë³„ë¡œ ë³„ë„ ê²°ê³¼ ë¦¬í„´

    return í˜•ì‹:
      [
        {
          "pill_index": 0,
          "bbox": [x1, y1, x2, y2],
          "topk": [
            {"rank": 1, "idx": ..., "dl_idx": "...", "prob": ...},
            ...
          ]
        },
        ...
      ]
    """
    img, boxes, confs = detect_yolo_boxes(img_path)

    results = []

    # YOLOê°€ ì•„ë¬´ê²ƒë„ ëª» ì¡ì•˜ìœ¼ë©´: ì´ë¯¸ì§€ ì „ì²´ë¥¼ "pill_index 0"ìœ¼ë¡œ ê°„ì£¼
    if not boxes:
        crops = [img.copy()]
        batch_results = predict_resnet_batch(crops, topk=topk)
        if batch_results:
            pred = batch_results[0]
            topk_list = []
            for rank, t in enumerate(pred, start=1):
                dl_idx = idx_to_dl_idx(t["idx"])
                topk_list.append({
                    "rank":   rank,
                    "idx":    t["idx"],
                    "dl_idx": dl_idx,
                    "prob":   t["prob"],
                })
            results.append({
                "pill_index": 0,
                "bbox": None,
                "topk": topk_list,
            })
        return results

    # conf ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ í›„ ìƒìœ„ max_pills ê°œ ì„ íƒ
    idx_sorted = sorted(range(len(boxes)), key=lambda i: confs[i], reverse=True)
    idx_keep   = idx_sorted[:max_pills]

    crops = []
    kept_boxes = []
    for i in idx_keep:
        bbox = boxes[i]
        sq = square_crop_from_bbox(img, bbox, scale=SQUARE_SCALE)
        if sq is None:
            continue
        crops.append(sq)
        kept_boxes.append(bbox)

    if not crops:
        # fallback: ì „ì²´ ì´ë¯¸ì§€ í•˜ë‚˜ë§Œ
        crops = [img.copy()]
        kept_boxes = [None]

    batch_results = predict_resnet_batch(crops, topk=topk)

    for pill_idx, (bbox, pred) in enumerate(zip(kept_boxes, batch_results)):
        topk_list = []
        for rank, t in enumerate(pred, start=1):
            dl_idx = idx_to_dl_idx(t["idx"])
            topk_list.append({
                "rank":   rank,
                "idx":    t["idx"],
                "dl_idx": dl_idx,
                "prob":   t["prob"],
            })
        results.append({
            "pill_index": pill_idx,
            "bbox": bbox,
            "topk": topk_list,
        })

    return results

# -------------------------------------------------
# 5) ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ ë™ì‘ ì˜ˆì‹œ
# -------------------------------------------------
if __name__ == "__main__":
    assert os.path.exists(IMG_PATH), f"ì´ë¯¸ì§€ ì—†ìŒ: {IMG_PATH}"

    print("\n=== [ë‹¨ì¼ ëª¨ë“œ] ì´ë¯¸ì§€ ì „ì²´ ê¸°ì¤€ ìµœì¢… Top-5 ===")
    single_res = infer_pill_image_single(IMG_PATH, topk_global=5)
    for r in single_res:
        print(
            f"Rank {r['rank']}: "
            f"class_idx={r['idx']}, dl_idx={r['dl_idx']}, prob={r['prob']*100:.2f}%"
        )

    print("\n=== [ë‹¤ì¤‘ ëª¨ë“œ] ìµœëŒ€ 4ê°œ ì•Œì•½ ê°ê°ì— ëŒ€í•œ Top-5 ===")
    multi_res = infer_pill_image_multi(IMG_PATH, max_pills=4, topk=5)
    for pill in multi_res:
        print(f"\n[Pill #{pill['pill_index']}] bbox={pill['bbox']}")
        for t in pill["topk"]:
            print(
                f"  Rank {t['rank']}: "
                f"class_idx={t['idx']}, dl_idx={t['dl_idx']}, prob={t['prob']*100:.2f}%"
            )

    # í•„ìš”í•˜ë©´ JSONìœ¼ë¡œ ì§ë ¬í™”í•´ì„œ ë‹¤ë¥¸ APIë¡œ ë„˜ê¸°ë©´ ë¨:
    # print(json.dumps(multi_res, ensure_ascii=False, indent=2))

from google.colab import drive
drive.mount('/content/drive')

!pip install ultralytics