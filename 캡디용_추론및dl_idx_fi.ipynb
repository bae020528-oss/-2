{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipibphMTYo2T",
        "outputId": "b27a2192-c53b-4579-fbbb-62acdc0fcf07"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.228-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.228-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.228 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojr4YRgSN-uv",
        "outputId": "a894efcd-16ab-4729-c657-432b8ca64924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "=== FINAL GLOBAL TOP-5 RESULTS ===\n",
            "Rank 1: class_idx=1262, dl_idx=9271, prob=99.22%\n",
            "Rank 2: class_idx=1070, dl_idx=18945, prob=2.75%\n",
            "Rank 3: class_idx=1275, dl_idx=9562, prob=1.05%\n",
            "Rank 4: class_idx=1308, dl_idx=38926, prob=0.64%\n",
            "Rank 5: class_idx=1229, dl_idx=13553, prob=0.43%\n"
          ]
        }
      ],
      "source": [
        "# === Fast Inference API (Optimized):\n",
        "#     YOLO â†’ (ì¡°ê±´ë¶€ ì „ì²´ì´ë¯¸ì§€ / ì†Œí”„íŠ¸ í¬ë¡­)\n",
        "#     â†’ ResNet(1324) ìµœì¢… Top-5 (dl_idx ê³„ì‚°ì‹ ê¸°ë°˜) ===\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 0) ê²½ë¡œ / ê¸°ë³¸ ì„¤ì •\n",
        "# -------------------------------------------------\n",
        "DRIVE = \"/content/drive/MyDrive\"\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ìš© ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (í•„ìš”í•˜ë©´ ì´ ê°’ë§Œ ë°”ê¿”ì„œ ì‚¬ìš©)\n",
        "IMG_PATH = \"/content/drive/MyDrive/á„á…¢á†¸á„‰á…³á„á…©á†«_á„‹á…¯á†«á„á…¥á†«_á„ƒá…¦á„‹á…µá„á…¥/TS_34_á„ƒá…¡á†«á„‹á…µá†¯.zip/K-009272/K-009272_0_1_0_0_70_000_200.png\"\n",
        "\n",
        "BEST_YOLO      = os.path.join(DRIVE, \"best.pt\")\n",
        "RESNET_1324_PT = os.path.join(DRIVE, \"best_model_generalized.pth\")\n",
        "CLASS_JSON_1K  = os.path.join(DRIVE, \"pill_label_path_sharp_score.json\")\n",
        "CLASS_JSON_324 = os.path.join(DRIVE, \"class_mapping_from_cache_1324.json\")\n",
        "\n",
        "for p in [BEST_YOLO, RESNET_1324_PT]:\n",
        "    assert os.path.exists(p), f\"ê°€ì¤‘ì¹˜ íŒŒì¼ ì—†ìŒ: {p}\"\n",
        "\n",
        "YOLO_CONF  = 0.25\n",
        "YOLO_IOU   = 0.45\n",
        "YOLO_IMGSZ = 640\n",
        "\n",
        "CROP_SIZE        = 224\n",
        "MIN_BOX_SIDE_PX  = 40\n",
        "FULL_IMAGE_AREA_RATIO_THRESHOLD = 0.65\n",
        "SQUARE_SCALE     = 1.3\n",
        "\n",
        "NUM_CLASSES  = 1324\n",
        "LABEL_OFFSET = 1000\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 1) ë¼ë²¨ ë§µ ë¡œë“œ (class_idx â†’ K-ì½”ë“œ)\n",
        "#    ê·¸ë¦¬ê³  ìµœì¢… dl_idxëŠ” \"K-xxxxxx\"ì˜ ë’¤ 6ìë¦¬ ì •ìˆ˜ - 1 ë¡œ ê³„ì‚°\n",
        "#    âš ï¸ ì´ ë¶€ë¶„ë„ í•œ ë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ ì „ì—­ì—ì„œ ì‹¤í–‰\n",
        "# -------------------------------------------------\n",
        "def load_label_map_generic(json_path):\n",
        "    \"\"\"\n",
        "    pill_label_path_sharp_score.json / class_mapping_from_cache_1324.json ì„ ì½ì–´ì„œ\n",
        "    class_idx â†’ Kì½”ë“œ(K-xxxxxx) ë§¤í•‘ì„ ë§Œë“ ë‹¤.\n",
        "    ê°’ì´ ê²½ë¡œ/íŒŒì¼ëª…ì¼ ê²½ìš° íŒŒì¼ëª…ì—ì„œ Kì½”ë“œë¥¼ íŒŒì‹±í•´ì„œ ì‚¬ìš©.\n",
        "    \"\"\"\n",
        "    if not json_path or not os.path.exists(json_path):\n",
        "        return {}\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    if isinstance(data, dict) and \"label_to_kcode\" in data:\n",
        "        data = data[\"label_to_kcode\"]\n",
        "\n",
        "    out = {}\n",
        "    if isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            try:\n",
        "                key_int = int(k)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            val_str = str(v)\n",
        "            base = os.path.basename(val_str)   # ì˜ˆ: \"K013101_0_2_0_1_90_020_200.png\"\n",
        "            first = base.split(\"_\")[0]         # ì˜ˆ: \"K013101\" ë˜ëŠ” \"K-009272\"\n",
        "\n",
        "            if first.startswith(\"K-\") and len(first) == 8 and first[2:].isdigit():\n",
        "                # ì´ë¯¸ \"K-009272\" ê°™ì€ í˜•ì‹\n",
        "                kcode = first\n",
        "            elif first.startswith(\"K\") and len(first) == 7 and first[1:].isdigit():\n",
        "                # \"K013101\" â†’ \"K-013101\"\n",
        "                kcode = \"K-\" + first[1:]\n",
        "            else:\n",
        "                # ê·¸ ì™¸ì—ëŠ” ê·¸ëƒ¥ ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš© (fallback)\n",
        "                kcode = first\n",
        "\n",
        "            out[key_int] = kcode\n",
        "\n",
        "    return out\n",
        "\n",
        "LABEL_MAP_1K  = load_label_map_generic(CLASS_JSON_1K)   # 0..999 â†’ Kì½”ë“œ\n",
        "LABEL_MAP_324 = load_label_map_generic(CLASS_JSON_324)  # 0..323 â†’ Kì½”ë“œ (1000~1323ìš©)\n",
        "\n",
        "def class_idx_to_kcode(global_idx: int) -> str:\n",
        "    \"\"\"\n",
        "    ëª¨ë¸ì˜ global class index â†’ Kì½”ë“œ(K-xxxxxx)ë¡œ ë³€í™˜\n",
        "    \"\"\"\n",
        "    if global_idx < LABEL_OFFSET:\n",
        "        return LABEL_MAP_1K.get(global_idx, f\"imagenet_{global_idx}\")\n",
        "    local = global_idx - LABEL_OFFSET\n",
        "    return LABEL_MAP_324.get(local, f\"unknown_{local}\")\n",
        "\n",
        "def kcode_to_dl_idx(kcode: str) -> str:\n",
        "    \"\"\"\n",
        "    Kì½”ë“œì—ì„œ dl_idx ê³„ì‚°:\n",
        "      ì˜ˆ) \"K-009272\" â†’ ë’¤ 6ìë¦¬ 009272 â†’ 9272 - 1 = 9271\n",
        "    ë§¤í•‘ íŒŒì¼ ì—†ì´ ê·œì¹™ìœ¼ë¡œë§Œ ê³„ì‚°.\n",
        "    \"\"\"\n",
        "    if len(kcode) >= 7:\n",
        "        tail = kcode[-6:]  # ë 6ìë¦¬\n",
        "        if tail.isdigit():\n",
        "            val = int(tail)\n",
        "            dl_val = val - 1\n",
        "            if dl_val >= 0:\n",
        "                return str(dl_val)\n",
        "    # ì‹¤íŒ¨ ì‹œ ê·¸ëƒ¥ ì›ë˜ ë¬¸ìì—´ ë°˜í™˜ (ë””ë²„ê·¸ìš©)\n",
        "    return kcode\n",
        "\n",
        "def idx_to_dl_idx(global_idx: int) -> str:\n",
        "    \"\"\"\n",
        "    class index â†’ Kì½”ë“œ â†’ dl_idx ë¡œ ë³€í™˜\n",
        "    \"\"\"\n",
        "    kcode = class_idx_to_kcode(global_idx)\n",
        "    return kcode_to_dl_idx(kcode)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 2) ResNet 1324 ëª¨ë¸ + ì „ì²˜ë¦¬ (ì „ì—­ 1íšŒ ë¡œë“œ)\n",
        "# -------------------------------------------------\n",
        "def build_resnet_1324(num_classes=NUM_CLASSES, model_path=RESNET_1324_PT):\n",
        "    model = models.resnet152(weights=None)\n",
        "    in_f = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(in_f, num_classes)\n",
        "    )\n",
        "\n",
        "    state = torch.load(model_path, map_location=\"cpu\")\n",
        "    if isinstance(state, dict):\n",
        "        if \"model_state_dict\" in state:\n",
        "            state = state[\"model_state_dict\"]\n",
        "        elif \"model\" in state:\n",
        "            state = state[\"model\"]\n",
        "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
        "    if missing or unexpected:\n",
        "        print(f\"â„¹ï¸ state_dict load: missing={len(missing)}, unexpected={len(unexpected)}\")\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    # GPUë©´ half precisionìœ¼ë¡œ ì‚´ì§ ë” ë¹ ë¥´ê²Œ\n",
        "    if DEVICE.type == \"cuda\":\n",
        "        model.half()\n",
        "\n",
        "    return model\n",
        "\n",
        "# ğŸ”¥ ì „ì—­ì—ì„œ í•œ ë²ˆë§Œ ìƒì„±í•´ì„œ ì¬ì‚¬ìš©\n",
        "RESNET_MODEL = build_resnet_1324()\n",
        "\n",
        "# ì „ì—­ transform (ì´ë¯¸ì§€ â†’ í…ì„œ)\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((CROP_SIZE, CROP_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "def preprocess_pil(pil_img):\n",
        "    t = base_transform(pil_img)\n",
        "    # ëª¨ë¸ì´ halfë©´ ì…ë ¥ë„ halfë¡œ ë§ì¶”ê¸°\n",
        "    if DEVICE.type == \"cuda\":\n",
        "        return t.half()\n",
        "    return t\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_resnet_batch(pil_imgs, topk=5):\n",
        "    \"\"\"\n",
        "    ì „ì—­ RESNET_MODEL ì‚¬ìš©.\n",
        "    pil_imgs: [PIL.Image, ...]\n",
        "    \"\"\"\n",
        "    if not pil_imgs:\n",
        "        return []\n",
        "    xs = [preprocess_pil(im) for im in pil_imgs]\n",
        "    x = torch.stack(xs).to(DEVICE)\n",
        "\n",
        "    # ì´ë¯¸ halfë¡œ ì˜¬ë ¤ë†¨ìœ¼ë©´ autocast í•„ìš” ì—†ìŒ â†’ ì˜¤ë²„í—¤ë“œ ì¤„ì´ê¸°\n",
        "    if DEVICE.type == 'cuda':\n",
        "        logits = RESNET_MODEL(x)\n",
        "    else:\n",
        "        with torch.amp.autocast(device_type='cpu'):\n",
        "            logits = RESNET_MODEL(x)\n",
        "\n",
        "    probs  = F.softmax(logits, dim=1)\n",
        "    topk_prob, topk_idx = torch.topk(probs, topk, dim=1)\n",
        "\n",
        "    all_results = []\n",
        "    for i in range(probs.shape[0]):\n",
        "        res_i = []\n",
        "        for p, idx in zip(topk_prob[i].tolist(), topk_idx[i].tolist()):\n",
        "            res_i.append({\n",
        "                \"idx\": int(idx),\n",
        "                \"prob\": float(p),\n",
        "            })\n",
        "        all_results.append(res_i)\n",
        "    return all_results\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3) YOLO ê°ì§€ + í¬ë¡­ ìƒì„± (ì „ì—­ YOLO 1íšŒ ë¡œë“œ, ë©”ëª¨ë¦¬ ìƒ ì²˜ë¦¬)\n",
        "# -------------------------------------------------\n",
        "# YOLOë„ ì „ì—­ì—ì„œ í•œ ë²ˆë§Œ ë¡œë“œ\n",
        "YOLO_DEVICE = 0 if DEVICE.type == \"cuda\" else \"cpu\"\n",
        "YOLO_MODEL = YOLO(BEST_YOLO)  # ultralyticsê°€ ë‚´ë¶€ì—ì„œ device ì¸ìì— ë”°ë¼ ì²˜ë¦¬\n",
        "\n",
        "def square_crop_from_bbox(pil_img, xyxy, scale=1.3):\n",
        "    W, H = pil_img.size\n",
        "    x1, y1, x2, y2 = xyxy\n",
        "    cx = (x1 + x2) / 2.0\n",
        "    cy = (y1 + y2) / 2.0\n",
        "    bw = x2 - x1\n",
        "    bh = y2 - y1\n",
        "    side = max(bw, bh) * scale\n",
        "\n",
        "    # ìµœì†Œ ì‚¬ì´ì¦ˆ ë³´ì¥\n",
        "    side = max(side, MIN_BOX_SIDE_PX * 1.5)\n",
        "\n",
        "    half = side / 2.0\n",
        "    nx1 = int(round(cx - half))\n",
        "    ny1 = int(round(cy - half))\n",
        "    nx2 = int(round(cx + half))\n",
        "    ny2 = int(round(cy + half))\n",
        "\n",
        "    nx1 = max(0, nx1)\n",
        "    ny1 = max(0, ny1)\n",
        "    nx2 = min(W, nx2)\n",
        "    ny2 = min(H, ny2)\n",
        "    if nx2 <= nx1 or ny2 <= ny1:\n",
        "        return None\n",
        "\n",
        "    crop = pil_img.crop((nx1, ny1, nx2, ny2))\n",
        "    return crop\n",
        "\n",
        "def make_crops_with_yolo(img_path):\n",
        "    \"\"\"\n",
        "    IMG_PATH í•˜ë‚˜ ë°›ì•„ì„œ:\n",
        "      - YOLOë¡œ bbox ê²€ì¶œ\n",
        "      - ë‹¨ì¼ + ê±°ì˜ ì „ì²´ ì°¨ì§€ë©´ full ì´ë¯¸ì§€ 1ì¥\n",
        "      - ê·¸ ì™¸ì—” square crop ì—¬ëŸ¬ ì¥\n",
        "    ê²°ê³¼: [PIL.Image, ...]\n",
        "    \"\"\"\n",
        "    assert os.path.exists(img_path), f\"ì´ë¯¸ì§€ ì—†ìŒ: {img_path}\"\n",
        "\n",
        "    det = YOLO_MODEL(\n",
        "        img_path,\n",
        "        imgsz=YOLO_IMGSZ,\n",
        "        conf=YOLO_CONF,\n",
        "        iou=YOLO_IOU,\n",
        "        device=YOLO_DEVICE,\n",
        "        verbose=False\n",
        "    )[0]\n",
        "\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    W, H = img.size\n",
        "    img_area = W * H\n",
        "\n",
        "    raw_boxes = []\n",
        "    if det.boxes is not None and len(det.boxes) > 0:\n",
        "        for b in det.boxes.xyxy.cpu().numpy().tolist():\n",
        "            x1, y1, x2, y2 = map(int, b)\n",
        "            x1 = max(0, x1)\n",
        "            y1 = max(0, y1)\n",
        "            x2 = min(W-1, x2)\n",
        "            y2 = min(H-1, y2)\n",
        "            if (x2-x1) >= MIN_BOX_SIDE_PX and (y2-y1) >= MIN_BOX_SIDE_PX:\n",
        "                raw_boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "    # ë‹¨ì¼ í° ë°•ìŠ¤ë©´ ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©\n",
        "    use_full_image_only = False\n",
        "    if len(raw_boxes) == 1:\n",
        "        x1, y1, x2, y2 = raw_boxes[0]\n",
        "        box_area = (x2-x1) * (y2-y1)\n",
        "        area_ratio = box_area / float(img_area + 1e-9)\n",
        "        if area_ratio >= FULL_IMAGE_AREA_RATIO_THRESHOLD:\n",
        "            use_full_image_only = True\n",
        "\n",
        "    crop_images = []\n",
        "\n",
        "    if use_full_image_only:\n",
        "        crop_images.append(img.copy())\n",
        "    else:\n",
        "        for bbox in raw_boxes:\n",
        "            sq = square_crop_from_bbox(img, bbox, scale=SQUARE_SCALE) if raw_boxes else None\n",
        "            if sq is None:\n",
        "                continue\n",
        "            crop_images.append(sq)\n",
        "\n",
        "    # YOLOê°€ ì•„ë¬´ê²ƒë„ ëª» ì¡ì•˜ìœ¼ë©´ ì „ì²´ ì´ë¯¸ì§€ fallback\n",
        "    if not crop_images:\n",
        "        crop_images.append(img.copy())\n",
        "\n",
        "    return crop_images\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 4) ì—”ë“œíˆ¬ì—”ë“œ ì¶”ë¡  í•¨ìˆ˜ (APIë¡œ ì“°ê¸° ì¢‹ê²Œ)\n",
        "# -------------------------------------------------\n",
        "def infer_pill_image(img_path: str, topk_global: int = 5):\n",
        "    \"\"\"\n",
        "    í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ê²½ë¡œ(img_path)ë¥¼ ë°›ì•„:\n",
        "      - YOLOë¡œ ì†Œí”„íŠ¸ í¬ë¡­ ì—¬ëŸ¬ ê°œ ìƒì„±\n",
        "      - ê° í¬ë¡­ì„ ResNet(1324)ë¡œ ì¶”ë¡ \n",
        "      - classë³„ max-poolingìœ¼ë¡œ ì „ì²´ ì´ë¯¸ì§€ ê¸°ì¤€ ìµœì¢… Top-K ê³„ì‚°\n",
        "      - ìµœì¢… ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ return\n",
        "\n",
        "    return í˜•ì‹:\n",
        "      [\n",
        "        {\"rank\": 1, \"idx\": <class_idx>, \"dl_idx\": \"<dl_idx>\", \"prob\": <float>},\n",
        "        ...\n",
        "      ]\n",
        "    \"\"\"\n",
        "    # 1) í¬ë¡­ ìƒì„±\n",
        "    crops = make_crops_with_yolo(img_path)\n",
        "\n",
        "    # 2) í¬ë¡­ë³„ Top-5 (ì „ì—­ RESNET_MODEL ì‚¬ìš©)\n",
        "    batch_results = predict_resnet_batch(crops, topk=topk_global)\n",
        "\n",
        "    # 3) í´ë˜ìŠ¤ë³„ max-pooling\n",
        "    agg_scores = {}  # class_idx â†’ max_prob\n",
        "    for crop_res in batch_results:\n",
        "        for t in crop_res:\n",
        "            idx = t[\"idx\"]\n",
        "            p   = t[\"prob\"]\n",
        "            if idx not in agg_scores or p > agg_scores[idx]:\n",
        "                agg_scores[idx] = p\n",
        "\n",
        "    if not agg_scores:\n",
        "        return []\n",
        "\n",
        "    # 4) ì „ì²´ ì´ë¯¸ì§€ ê¸°ì¤€ ìµœì¢… Top-K\n",
        "    sorted_pairs = sorted(agg_scores.items(), key=lambda x: x[1], reverse=True)[:topk_global]\n",
        "\n",
        "    final_results = []\n",
        "    for rank, (idx, prob) in enumerate(sorted_pairs, start=1):\n",
        "        dl_idx = idx_to_dl_idx(idx)\n",
        "        final_results.append({\n",
        "            \"rank\":  rank,\n",
        "            \"idx\":   idx,\n",
        "            \"dl_idx\": dl_idx,\n",
        "            \"prob\":  prob,\n",
        "        })\n",
        "\n",
        "    return final_results\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 5) ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ ë™ì‘ ì˜ˆì‹œ\n",
        "# -------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    assert os.path.exists(IMG_PATH), f\"ì´ë¯¸ì§€ ì—†ìŒ: {IMG_PATH}\"\n",
        "    results = infer_pill_image(IMG_PATH, topk_global=5)\n",
        "\n",
        "    # âœ… APIì— ë„˜ê¸¸ ê°’ì€ ì´ results ê·¸ëŒ€ë¡œ ì“°ë©´ ë¨\n",
        "    print(\"=== FINAL GLOBAL TOP-5 RESULTS ===\")\n",
        "    for r in results:\n",
        "        print(\n",
        "            f\"Rank {r['rank']}: \"\n",
        "            f\"class_idx={r['idx']}, dl_idx={r['dl_idx']}, prob={r['prob']*100:.2f}%\"\n",
        "        )\n",
        "    # import json\n",
        "    # print(json.dumps(results, ensure_ascii=False, indent=2))\n"
      ]
    }
  ]
}